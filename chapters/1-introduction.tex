\chapter{Introduction}\label{chap:introduction}

\section{Background of the Problem}\label{sec:Background motivation of the problem}
    \paragraph{}Depth estimation is a cornerstone task in the realm of computer vision, with a wide array of applications, including 3D reconstruction, autonomous navigation, augmented reality, 3D printing, computational photography, computer video games, and preservation of cultural heritage. As we advance into an era defined by data and artificial intelligence, the importance of developing robust and efficient depth estimation models is paramount. When materials, viewpoints, and lighting conditions are well-defined, the task becomes more tractable. However, if any of these factors are not known, the problem typically becomes ill-posed. This is because a variety of combinations that involve geometry, materials, viewpoints, and lighting can result in identical photographs. In such cases, the ambiguity introduced by these unknown variables makes it difficult to uniquely determine the exact characteristics of the scene from the given images.\par 
    Humans possess an impressive capacity to solve such inverse problems, even when the solutions are uncertain. We can draw on our prior knowledge to make estimations about the size, arrangement, and coarse proximity of objects in the environment in relation to our own position and between the objects themselves. This proficiency can be attributed to previous experiential interactions with diverse objects and contexts, culminating in constructing cognitive priors that facilitate an insightful understanding of the visual attributes and spatial interconnections within the three-dimensional world around us. For decades, computer scientists have worked hard to recreate this amazing ability that we take for granted to enable computers to do the same. Inspired by the human binocular vision system, stereo matching and its extension {\mvs} (MVS)\cite{Seitz2006} based depth estimation models have garnered immense attention. In particular, {\mvs} models have become extremely successful due to their ability to take advantage of multiple views of a scene to produce accurate depth maps. \par
    While traditional {\mvs} methods have been successful to some extent, they often rely heavily on handcrafted features and similarity measures. This leads them to have limitations in handling poorly textured regions, and the models may struggle with occlusions or varying lighting conditions. With the rise of deep learning and especially Convolutional Neural Networks (CNN)\cite{lecun1997} and in recent years, the Visual Transformer(ViT)\cite{dosovitskiy2021image, ranftl2021vision, amir2021deep}, depth estimation has seen a paradigm shift, with models now capable of learning features directly from data and achieving superior performance. This, combined with the growing accessibility of extensive training datasets, has opened a new era of {\mvs} methodologies\cite{Seitz2006}. These approaches address the complex inverse problem of inferring depth information from RGB images.\par
    However, it has been observed in practice that the performance of these models depends on various factors, such as the underlying network architecture, training datasets, data augmentations, and several hyperparameters of the network and training setup. It has also been observed that models trained on a specific data modality do not generalize well to other modalities without significant adaptations and fine-tuning. This robustness characteristic is extremely important in the real world. In practical settings involving multi-camera layouts, we often have access to camera positions but lack depth range and alignment details of the ground truth and the predicted depth maps. Deep learning MVS methodologies aim to accurately determine relevant depth maps and their appropriate scales from this stream of visual data.\par 
    In this thesis, we explore which combinations of the factors mentioned above yield superior generalization results through different data modalities, particularly in challenging situations such as areas with intricate structures, sections without texture, reflective surfaces, zones with pronounced gradients, scenes involving minor camera movements, and instances of occlusions.


\section{A Brief Overview of \rmvd}\label{sec:A brief overview of \rmvd}
    \paragraph{}In this study, we take a closer look at the {\framework} framework\cite{schroeppel2022benchmark}, which provides a common ground to evaluate {\mv} depth models on their generalization capabilities in various domains. The framework has also given us the {\dispn} based {\rmvd} depth estimation model and a novel input image data augmentation technique called \textit{Scale Augmentation}\cite{schroeppel2022benchmark}. This approach has attracted much attention in the community by demonstrating robust cross-domain scale-agnostic {\mv} depth estimation.\par
    The framework also introduces the {\framework} benchmark \cite{schroeppel2022benchmark} founded on existing datasets with different modalities. This benchmark offers a three-fold evaluation protocol. Firstly, it gauges the performance of estimated depth maps across distinct data domains through a zero-shot assessment paradigm. Second, it quantifies uncertainties using the Area-Under-the-Sparsification-Error-Curve (AUSE)\cite{Ilg2018} metric. Additionally, the benchmark encompasses an absolute evaluation scenario motivated by practical use cases, where precise camera poses are provided to the model. The benchmark emphasizes depth estimation's generalization capabilities rather than just performance on specific datasets. It is proposed as an additional evaluation tool alongside traditional benchmarks such as KITTI, ScanNet, DTU, Tanks and Temples, and others. Overall, {\framework} offers a comprehensive platform to evaluate the generalization capabilities of depth estimation models in various domains, addressing both depth prediction and associated uncertainties.\par
    Despite the effectiveness of the {\rmvd} framework, the complexity and multifaceted nature of the {\mvs} raise several intriguing questions. How do individual components of the network architecture impact overall performance? What is the role of input data augmentations, and how do they affect the model's ability to generalize? How do the choice of data sets and the properties of the data influence performance? Also, how do the various hyperparameters of the models and the training setup steer the accuracy and efficiency of the models? \par

\section{Ablation Study and its Objectives}\label{sec:Ablation study and its objectives}
    \paragraph{}In this thesis, we aim to address these questions systematically. To this end, we conducted an extensive ablation study with the {\rmvd} framework, where we investigated the contribution of each of these components and factors to the overall performance of the model. We implemented different models within the {\rmvd} framework, each designed with different network architecture components. The API is written in a manner that makes it easier to conduct experiments in a plug-and-play fashion by making the interfaces of the different architectural components and the data loading for different datasets compatible. We then evaluate the impact of different input augmentations and assess the effect of training these models on various datasets in a known depth range setting. Furthermore, we consider a range of data properties, such as the number and sampling strategy of source views, and perform an in-depth exploration of the impacts of altering different hyperparameters in the network and training setup.\par
    Through our ablation study, we aim to shed light on the intricacies of depth estimation using {\mvs} and contribute to the understanding of the principles driving the performance of {\mv} depth estimation models. By identifying the most influential factors, we aim to inform the design of future models and enhance the effectiveness of depth estimation methodologies. 

\section{Report Structure}\label{sec:Report Structure}
    \paragraph{}The rest of this report is organized as follows: In \hyperref[chap:background]{Chapter 2}, we revisit the fundamental concepts of {\mv} geometry, disparity, and depth estimation in a {\mv} setting. We also have a detailed study of a typical {\mvs} depth estimation pipeline to explain the terminology used in this thesis. In \hyperref[chap:relatedwork]{Chapter 3}, we conduct a thorough literature review of existing research in the domain of depth estimation in an MVS setting. In \hyperref[chap:approach]{Chapter 4}, we present the details of our experimental setup, datasets, and model performance evaluation metrics. In \hyperref[chap:experiments]{Chapter 5} we discuss the results of our ablation study, organized by factors under consideration: \textbf{1)} \hyperref[sec:exp-arch]{network architecture components}, \textbf{2)} \hyperref[sec:exp-dataset-prop]{datasets, their properties and augmentations} and \textbf{3)} \hyperref[sec:exp-hyper]{hyperparameters of the training setup}. Finally, in \hyperref[chap:conclusion]{Chapter 6}, we draw conclusions from our findings and discuss potential avenues for future research in this domain. Model implementation details and quantitative analyses are presented in the \hyperref[chap:appendix]{Appendix}.


